{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68cafe96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trino in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from -r requirements.txt (line 1)) (0.336.0)\n",
      "Requirement already satisfied: pandas in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from -r requirements.txt (line 2)) (2.3.3)\n",
      "Requirement already satisfied: lz4 in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from trino->-r requirements.txt (line 1)) (4.4.4)\n",
      "Requirement already satisfied: orjson>=3.11.0 in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from trino->-r requirements.txt (line 1)) (3.11.4)\n",
      "Requirement already satisfied: python-dateutil in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from trino->-r requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from trino->-r requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: requests>=2.32.4 in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from trino->-r requirements.txt (line 1)) (2.32.5)\n",
      "Requirement already satisfied: tzlocal in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from trino->-r requirements.txt (line 1)) (5.3.1)\n",
      "Requirement already satisfied: zstandard in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from trino->-r requirements.txt (line 1)) (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2.3.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from pandas->-r requirements.txt (line 2)) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from python-dateutil->trino->-r requirements.txt (line 1)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from requests>=2.32.4->trino->-r requirements.txt (line 1)) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from requests>=2.32.4->trino->-r requirements.txt (line 1)) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from requests>=2.32.4->trino->-r requirements.txt (line 1)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\code\\git\\cs6604-trafficsafety\\.conda\\lib\\site-packages (from requests>=2.32.4->trino->-r requirements.txt (line 1)) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8be8c6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from trino import dbapi\n",
    "from trino.auth import OAuth2Authentication\n",
    "\n",
    "conn = dbapi.connect(\n",
    "    host=\"smart-cities-trino.pre-prod.cloud.vtti.vt.edu\",\n",
    "    port=443,\n",
    "    http_scheme=\"https\",\n",
    "    auth=OAuth2Authentication(),   # <-- this is the right one\n",
    "    catalog=\"smartcities_iceberg\",  # optional default\n",
    "    # schema=\"...\",                # optional default\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "366f8169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open the following URL in browser for the external authentication:\n",
      "https://smart-cities-trino.pre-prod.cloud.vtti.vt.edu/oauth2/token/initiate/1ef0d9d32250a69654c2ab03667bebaf209a9e81962f545c80ee0980d09aa9a0\n",
      "[['alexandria'], ['cci'], ['falls-church'], ['information_schema'], ['smart_cities_test'], ['system'], ['tables'], ['vtti']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"SHOW SCHEMAS\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "835a08a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['smartcities_iceberg'], ['system']]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SHOW CATALOGS\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ecbca743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['alexandria'], ['cci'], ['falls-church'], ['information_schema'], ['smart_cities_test'], ['system'], ['tables'], ['vtti']]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"SHOW SCHEMAS FROM smartcities_iceberg\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "05016733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['alexandria', 'bsm'], ['alexandria', 'psm'], ['alexandria', 'safety-event'], ['alexandria', 'speed-distribution'], ['alexandria', 'vehicle-count'], ['alexandria', 'vru-count'], ['cci', 'bsm'], ['falls-church', 'hiresdata'], ['falls-church', 'maple_washington'], ['falls-church', 'mediantraveltimes'], ['falls-church', 'old_hiresdata'], ['falls-church', 'old_mediantraveltimes'], ['falls-church', 'old_priority_requests'], ['falls-church', 'old_safety_conflicts'], ['falls-church', 'old_safety_pedcompliance'], ['falls-church', 'old_safety_redlightrunners'], ['falls-church', 'old_safety_simpledelay'], ['falls-church', 'old_tmc'], ['falls-church', 'old_tmc_crosswalk'], ['falls-church', 'old_tmc_lanes']]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"\n",
    "SELECT table_schema, table_name\n",
    "FROM smartcities_iceberg.information_schema.tables\n",
    "ORDER BY table_schema, table_name\n",
    "LIMIT 20\n",
    "\"\"\")\n",
    "print(cur.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wye8zdjkqxq",
   "metadata": {},
   "source": "## Best Practices for Querying\n\n### 1. Always Verify Column Names First\n\n**CRITICAL:** Column names may not be what you expect! Run the schema verification cells in this notebook to see actual field names.\n\n```python\n# See actual columns in a table\ncur.execute(\"SELECT * FROM smartcities_iceberg.alexandria.bsm LIMIT 1\")\nactual_columns = [desc[0] for desc in cur.description]\nprint(actual_columns)\n```\n\n**Common Issues:**\n- ❌ `vehicle_id` may not exist\n- ❌ `latitude`, `longitude` → Use `lat`, `lon` instead\n- ✅ Always check the schema verification output first!\n\n### 2. Use Cursor Method (Not pd.read_sql)\n\nTo avoid pandas SQLAlchemy warnings, use the cursor method:\n\n```python\n# Good: Use cursor method\ncur.execute(\"SELECT * FROM table LIMIT 5\")\ncolumns = [desc[0] for desc in cur.description]\nresults = cur.fetchall()\ndf = pd.DataFrame(results, columns=columns)\n\n# Avoid: pd.read_sql() triggers warning\n# df = pd.read_sql(\"SELECT * FROM table\", conn)\n```\n\n### 3. Start with SELECT *\n\nWhen exploring or unsure about column names, use `SELECT *` to get all columns:\n\n```sql\nSELECT \n    from_unixtime(publish_timestamp / 1000) as timestamp,\n    *\nFROM smartcities_iceberg.alexandria.bsm\nLIMIT 10\n```\n\nThen filter columns in pandas:\n```python\ndf_filtered = df[['timestamp', 'lat', 'lon', 'speed']]\n```\n\n### 4. Handle publish_timestamp Correctly\n\n`publish_timestamp` is a **bigint** (milliseconds since Unix epoch), NOT a timestamp type.\n\n**Convert to readable timestamp:**\n```sql\nfrom_unixtime(publish_timestamp / 1000) as timestamp\n```\n\n**Filter by time:**\n```sql\nWHERE publish_timestamp >= to_unixtime(current_timestamp - interval '24' hour) * 1000\n```\n\n**Use in aggregations:**\n```sql\ndate_trunc('hour', from_unixtime(publish_timestamp / 1000))\n```"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "s0nvwsudvfk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tables found: 51\n",
      "\n",
      "           Schema                      Table\n",
      "       alexandria                        bsm\n",
      "       alexandria                        psm\n",
      "       alexandria               safety-event\n",
      "       alexandria         speed-distribution\n",
      "       alexandria              vehicle-count\n",
      "       alexandria                  vru-count\n",
      "              cci                        bsm\n",
      "     falls-church                  hiresdata\n",
      "     falls-church           maple_washington\n",
      "     falls-church          mediantraveltimes\n",
      "     falls-church              old_hiresdata\n",
      "     falls-church      old_mediantraveltimes\n",
      "     falls-church      old_priority_requests\n",
      "     falls-church       old_safety_conflicts\n",
      "     falls-church   old_safety_pedcompliance\n",
      "     falls-church old_safety_redlightrunners\n",
      "     falls-church     old_safety_simpledelay\n",
      "     falls-church                    old_tmc\n",
      "     falls-church          old_tmc_crosswalk\n",
      "     falls-church              old_tmc_lanes\n",
      "     falls-church           safety-conflicts\n",
      "     falls-church               safety-event\n",
      "     falls-church              safety-event \n",
      "     falls-church     safety-redlightrunners\n",
      "     falls-church         safety-simpledelay\n",
      "     falls-church         speed-distribution\n",
      "     falls-church        speed-distribution \n",
      "     falls-church                        tmc\n",
      "     falls-church              tmc-crosswalk\n",
      "     falls-church                  tmc-lanes\n",
      "     falls-church              vehicle-count\n",
      "     falls-church             vehicle-count \n",
      "     falls-church                  vru-count\n",
      "     falls-church                 vru-count \n",
      "smart_cities_test                   bsm_data\n",
      "smart_cities_test            bsm_data_struct\n",
      "smart_cities_test              bsm_wide_data\n",
      "smart_cities_test                   psm_data\n",
      "smart_cities_test                   rse_data\n",
      "smart_cities_test                  spat_data\n",
      "smart_cities_test           table_properties\n",
      "           tables                        bsm\n",
      "           tables                        psm\n",
      "             vtti                environment\n",
      "             vtti          environment-alarm\n",
      "             vtti                      light\n",
      "             vtti                light-alarm\n",
      "             vtti                      noise\n",
      "             vtti                noise-alarm\n",
      "             vtti                    traffic\n",
      "             vtti              traffic-alarm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get all tables from all schemas\n",
    "cur.execute(\"\"\"\n",
    "SELECT table_schema, table_name\n",
    "FROM smartcities_iceberg.information_schema.tables\n",
    "WHERE table_schema NOT IN ('information_schema', 'system')\n",
    "ORDER BY table_schema, table_name\n",
    "\"\"\")\n",
    "all_tables = cur.fetchall()\n",
    "\n",
    "tables_df = pd.DataFrame(all_tables, columns=['Schema', 'Table'])\n",
    "print(f\"Total tables found: {len(tables_df)}\\n\")\n",
    "print(tables_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "l1b64brjzm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ALEXANDRIA SCHEMA - BSM Table\n",
      "================================================================================\n",
      "                      Column  Data Type\n",
      "0                       city    varchar\n",
      "1               intersection    varchar\n",
      "2                      table    varchar\n",
      "3          publish_timestamp     bigint\n",
      "4              location_name    varchar\n",
      "5                source_type    varchar\n",
      "6                vendor_name    varchar\n",
      "7             vendor_version    varchar\n",
      "8                       misc    varchar\n",
      "9                    msg_cnt    integer\n",
      "10                        id     bigint\n",
      "11                  sec_mark    integer\n",
      "12                       lat     double\n",
      "13                       lon     double\n",
      "14                      elev       real\n",
      "15       accuracy_semi_major       real\n",
      "16       accuracy_semi_minor       real\n",
      "17      accuracy_orientation       real\n",
      "18              transmission    integer\n",
      "19                     speed       real\n",
      "20                   heading       real\n",
      "21                     angle       real\n",
      "22                 accel_lon       real\n",
      "23                 accel_lat       real\n",
      "24                accel_vert       real\n",
      "25                 accel_yaw       real\n",
      "26      brake_applied_status    integer\n",
      "27   traction_control_status    integer\n",
      "28    anti_lock_brake_status    integer\n",
      "29  stability_control_status    integer\n",
      "30       brake_boost_applied    integer\n",
      "31    auxiliary_brake_status    integer\n",
      "32                size_width    integer\n",
      "33               size_length    integer\n",
      "34     original_content_type    varchar\n",
      "35          original_content  varbinary\n"
     ]
    }
   ],
   "source": [
    "# Function to examine table structure\n",
    "def describe_table(schema, table):\n",
    "    cur.execute(f\"\"\"\n",
    "    SELECT column_name, data_type\n",
    "    FROM smartcities_iceberg.information_schema.columns\n",
    "    WHERE table_schema = '{schema}' AND table_name = '{table}'\n",
    "    ORDER BY ordinal_position\n",
    "    \"\"\")\n",
    "    columns = cur.fetchall()\n",
    "    return pd.DataFrame(columns, columns=['Column', 'Data Type'])\n",
    "\n",
    "\n",
    "# Let's examine some key tables from each schema\n",
    "print(\"=\" * 80)\n",
    "print(\"ALEXANDRIA SCHEMA - BSM Table\")\n",
    "print(\"=\" * 80)\n",
    "print(describe_table('alexandria', 'bsm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "058ts384lm93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ALEXANDRIA SCHEMA - PSM Table (Pedestrian Safety Message)\n",
      "================================================================================\n",
      "                  Column  Data Type\n",
      "0                   city    varchar\n",
      "1           intersection    varchar\n",
      "2                  table    varchar\n",
      "3      publish_timestamp     bigint\n",
      "4          location_name    varchar\n",
      "5            source_type    varchar\n",
      "6            vendor_name    varchar\n",
      "7         vendor_version    varchar\n",
      "8                   misc    varchar\n",
      "9                msg_cnt    integer\n",
      "10            basic_type    integer\n",
      "11                    id     bigint\n",
      "12              sec_mark    integer\n",
      "13                   lat     double\n",
      "14                   lon     double\n",
      "15                  elev       real\n",
      "16   accuracy_semi_major       real\n",
      "17   accuracy_semi_minor       real\n",
      "18  accuracy_orientation       real\n",
      "19                 speed       real\n",
      "20               heading       real\n",
      "21             accel_lon       real\n",
      "22             accel_lat       real\n",
      "23            accel_vert       real\n",
      "24             accel_yaw       real\n",
      "25  event_responder_type    integer\n",
      "26         activity_type    integer\n",
      "27     activity_sub_type    integer\n",
      "28      original_content  varbinary\n",
      "\n",
      "================================================================================\n",
      "ALEXANDRIA SCHEMA - Safety Event Table\n",
      "================================================================================\n",
      "               Column Data Type\n",
      "0          event_type   varchar\n",
      "1            event_id   varchar\n",
      "2        time_at_site    bigint\n",
      "3      detection_area   varchar\n",
      "4           camera_id   varchar\n",
      "5           direction   varchar\n",
      "6            movement   varchar\n",
      "7       object1_class   varchar\n",
      "8       object2_class   varchar\n",
      "9                city   varchar\n",
      "10       intersection   varchar\n",
      "11              table   varchar\n",
      "12  publish_timestamp    bigint\n",
      "\n",
      "================================================================================\n",
      "ALEXANDRIA SCHEMA - Vehicle Count Table\n",
      "================================================================================\n",
      "              Column Data Type\n",
      "0              count   integer\n",
      "1               date   varchar\n",
      "2      time_interval   varchar\n",
      "3           approach   varchar\n",
      "4              class   varchar\n",
      "5               city   varchar\n",
      "6       intersection   varchar\n",
      "7              table   varchar\n",
      "8  publish_timestamp    bigint\n",
      "9           movement   varchar\n",
      "\n",
      "================================================================================\n",
      "FALLS CHURCH SCHEMA - HiRes Data Table\n",
      "================================================================================\n",
      "               Column Data Type\n",
      "0                city   varchar\n",
      "1       data_provider   varchar\n",
      "2               table   varchar\n",
      "3     intersection_id   varchar\n",
      "4        intersection   varchar\n",
      "5   intersection_name   varchar\n",
      "6    intersection_lat    double\n",
      "7   intersection_long    double\n",
      "8   publish_timestamp    bigint\n",
      "9     event_timestamp    bigint\n",
      "10         event_code   integer\n",
      "11        event_param   integer\n",
      "12   original_content   varchar\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ALEXANDRIA SCHEMA - PSM Table (Pedestrian Safety Message)\")\n",
    "print(\"=\" * 80)\n",
    "print(describe_table('alexandria', 'psm'))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ALEXANDRIA SCHEMA - Safety Event Table\")\n",
    "print(\"=\" * 80)\n",
    "print(describe_table('alexandria', 'safety-event'))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ALEXANDRIA SCHEMA - Vehicle Count Table\")\n",
    "print(\"=\" * 80)\n",
    "print(describe_table('alexandria', 'vehicle-count'))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FALLS CHURCH SCHEMA - HiRes Data Table\")\n",
    "print(\"=\" * 80)\n",
    "print(describe_table('falls-church', 'hiresdata'))"
   ]
  },
  {
   "cell_type": "code",
   "id": "0s688l7vb3bo",
   "source": "# Store schemas in variables for later use to ensure correct field names\nprint(\"=\" * 80)\nprint(\"STORING SCHEMAS FOR KEY TABLES\")\nprint(\"=\" * 80)\n\n# Get and store BSM schema\nbsm_schema = describe_table('alexandria', 'bsm')\nprint(\"\\nAlexandria BSM Schema:\")\nprint(bsm_schema.to_string(index=False))\nbsm_columns = bsm_schema['Column'].tolist()\n\n# Get and store PSM schema\npsm_schema = describe_table('alexandria', 'psm')\nprint(\"\\n\\nAlexandria PSM Schema:\")\nprint(psm_schema.to_string(index=False))\npsm_columns = psm_schema['Column'].tolist()\n\n# Get and store Safety Event schema\nsafety_event_schema = describe_table('alexandria', 'safety-event')\nprint(\"\\n\\nAlexandria Safety Event Schema:\")\nprint(safety_event_schema.to_string(index=False))\nsafety_event_columns = safety_event_schema['Column'].tolist()\n\n# Get and store Vehicle Count schema\nvehicle_count_schema = describe_table('alexandria', 'vehicle-count')\nprint(\"\\n\\nAlexandria Vehicle Count Schema:\")\nprint(vehicle_count_schema.to_string(index=False))\nvehicle_count_columns = vehicle_count_schema['Column'].tolist()\n\n# Get and store Falls Church HiRes Data schema\nhiresdata_schema = describe_table('falls-church', 'hiresdata')\nprint(\"\\n\\nFalls Church HiRes Data Schema:\")\nprint(hiresdata_schema.to_string(index=False))\nhiresdata_columns = hiresdata_schema['Column'].tolist()\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"Schemas stored! Use these column lists to ensure correct field names in queries.\")\nprint(\"=\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "tkmtv24xpwd",
   "source": "# Helper function to check if columns exist in a table\ndef check_columns(columns_to_check, available_columns, table_name):\n    \"\"\"\n    Verify that requested columns exist in the table schema\n    \n    Args:\n        columns_to_check: List of column names you want to use\n        available_columns: List of actual columns from the schema\n        table_name: Name of the table (for error messages)\n    \n    Returns:\n        tuple: (all_valid: bool, missing_columns: list)\n    \"\"\"\n    missing = [col for col in columns_to_check if col not in available_columns]\n    \n    if missing:\n        print(f\"WARNING: The following columns do not exist in {table_name}:\")\n        print(f\"  Missing: {missing}\")\n        print(f\"  Available columns: {available_columns}\")\n        return False, missing\n    else:\n        print(f\"✓ All columns exist in {table_name}\")\n        return True, []\n\n# Example: Verify BSM columns before using them\nprint(\"Example: Checking if columns exist in BSM table:\")\ncolumns_i_want = ['publish_timestamp', 'vehicle_id', 'lat', 'lon', 'speed', 'heading']\ncheck_columns(columns_i_want, bsm_columns, 'alexandria.bsm')\n\n# Show common column name corrections\nprint(\"\\n\" + \"=\" * 80)\nprint(\"COMMON FIELD NAME CORRECTIONS:\")\nprint(\"=\" * 80)\nprint(\"BSM Table:\")\nprint(\"  ✗ latitude  → ✓ lat\")\nprint(\"  ✗ longitude → ✓ lon\")\nprint(\"\\nSafety Event Table:\")\nprint(\"  ✗ latitude  → ✓ lat\")\nprint(\"  ✗ longitude → ✓ lon\")\nprint(\"=\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "t31t48pbqz",
   "source": "## Using Stored Schemas\n\nThe schemas for key tables are now stored in variables:\n- `bsm_columns` - List of columns in alexandria.bsm\n- `psm_columns` - List of columns in alexandria.psm\n- `safety_event_columns` - List of columns in alexandria.safety-event\n- `vehicle_count_columns` - List of columns in alexandria.vehicle-count\n- `hiresdata_columns` - List of columns in falls-church.hiresdata\n\n**Always verify column names before writing queries** to avoid errors!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "30hy3yg34xj",
   "source": "# Example: Dynamically build a query using stored schema\ndef build_select_query(table_schema, table_name, columns_to_select, available_columns, limit=10):\n    \"\"\"\n    Build a SELECT query dynamically after verifying columns exist\n    \n    Args:\n        table_schema: Schema name (e.g., 'alexandria')\n        table_name: Table name (e.g., 'bsm')\n        columns_to_select: List of columns to select\n        available_columns: List of available columns from schema\n        limit: Number of rows to return\n    \n    Returns:\n        str: SQL query string or None if columns are invalid\n    \"\"\"\n    # Verify all columns exist\n    is_valid, missing = check_columns(columns_to_select, available_columns, f\"{table_schema}.{table_name}\")\n    \n    if not is_valid:\n        print(f\"Cannot build query - missing columns: {missing}\")\n        return None\n    \n    # Build column list\n    column_str = \", \".join(columns_to_select)\n    \n    # Build query\n    query = f\"\"\"\n    SELECT {column_str}\n    FROM smartcities_iceberg.{table_schema}.\"{table_name}\"\n    LIMIT {limit}\n    \"\"\"\n    \n    return query\n\n# Example: Build a safe BSM query\nprint(\"Building a query for BSM data:\")\ncolumns_needed = ['publish_timestamp', 'vehicle_id', 'lat', 'lon', 'speed']\nquery = build_select_query('alexandria', 'bsm', columns_needed, bsm_columns, limit=5)\n\nif query:\n    print(\"\\nGenerated Query:\")\n    print(query)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "aolrfk0z9xu",
   "source": "# Let's see what the ACTUAL column names are by querying sample data\nprint(\"=\" * 80)\nprint(\"VERIFYING ACTUAL COLUMN NAMES IN BSM TABLE\")\nprint(\"=\" * 80)\n\n# Get a sample row to see actual column names\ncur.execute(\"\"\"\nSELECT *\nFROM smartcities_iceberg.alexandria.bsm\nLIMIT 1\n\"\"\")\n\n# Get actual column names from the query result\nactual_bsm_columns = [desc[0] for desc in cur.description]\nprint(f\"\\nActual columns in BSM table ({len(actual_bsm_columns)} total):\")\nfor i, col in enumerate(actual_bsm_columns, 1):\n    print(f\"  {i:2d}. {col}\")\n\n# Store for comparison\nprint(f\"\\nColumns stored from schema query: {len(bsm_columns)} total\")\nif set(actual_bsm_columns) != set(bsm_columns):\n    print(\"WARNING: Mismatch between schema query and actual columns!\")\nelse:\n    print(\"✓ Schema matches actual columns\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d9qoqv9q8",
   "source": "# Check Safety Event columns too\nprint(\"\\n\" + \"=\" * 80)\nprint(\"VERIFYING ACTUAL COLUMN NAMES IN SAFETY-EVENT TABLE\")\nprint(\"=\" * 80)\n\ncur.execute(\"\"\"\nSELECT *\nFROM smartcities_iceberg.alexandria.\"safety-event\"\nLIMIT 1\n\"\"\")\n\nactual_safety_columns = [desc[0] for desc in cur.description]\nprint(f\"\\nActual columns in Safety-Event table ({len(actual_safety_columns)} total):\")\nfor i, col in enumerate(actual_safety_columns, 1):\n    print(f\"  {i:2d}. {col}\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"STORE THESE VERIFIED COLUMNS FOR USE IN QUERIES\")\nprint(\"=\" * 80)\nprint(f\"\\nbsm_columns_verified = {actual_bsm_columns}\")\nprint(f\"\\nsafety_event_columns_verified = {actual_safety_columns}\")\n\n# Update the stored columns with verified ones\nbsm_columns = actual_bsm_columns\nsafety_event_columns = actual_safety_columns",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "csnfcywl3x",
   "source": "## ⚠️ IMPORTANT: Workflow for Using This Notebook\n\n**Before running the example queries below, you MUST:**\n\n1. **Run ALL cells in order** from the beginning of the notebook\n2. **Pay special attention to the schema verification cells** (above) which show you the ACTUAL column names\n3. **Note the actual column names** displayed in the verification output\n4. **Update queries** to use the correct column names based on what you see\n\n### Common Issues:\n- ❌ Assuming field names like `vehicle_id`, `latitude`, `longitude` \n- ✅ Use the ACTUAL field names shown in the verification cells above\n- ❌ Using `timestamp` instead of `publish_timestamp` for filtering\n- ✅ `publish_timestamp` is a **bigint** (milliseconds) - use conversion functions\n\n### Safe Approach:\nAll example queries below now use `SELECT *` to get ALL columns. After seeing what's available, you can filter to specific columns in your DataFrame:\n\n```python\n# After running a query with SELECT *\ndf_filtered = df[['column1', 'column2', 'column3']]\n```",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "argzlf026c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA AVAILABILITY AND TIME RANGES\n",
      "================================================================================\n",
      "\n",
      "Checking alexandria.bsm...\n",
      "  Error: Could not convert '+57641-08-14 10:06:55.000 America/New_York' into the associated python type\n",
      "\n",
      "Checking alexandria.psm...\n",
      "  Error: Could not convert '+57644-02-14 14:15:42.000 America/New_York' into the associated python type\n",
      "\n",
      "Checking alexandria.safety-event...\n",
      "  Error: Could not convert '+57527-01-15 15:25:49.000 America/New_York' into the associated python type\n",
      "\n",
      "Checking alexandria.vehicle-count...\n",
      "  Error: Could not convert '+57527-02-26 06:51:24.000 America/New_York' into the associated python type\n",
      "\n",
      "Checking falls-church.hiresdata...\n",
      "  Error: TrinoUserError(type=USER_ERROR, name=SYNTAX_ERROR, message=\"line 6:39: mismatched input '-'. Expecting: ',', '.', 'AS', 'CROSS', 'EXCEPT', 'FETCH', 'FOR', 'FULL', 'GROUP', 'HAVING', 'INNER', 'INTERSECT', 'JOIN', 'LEFT', 'LIMIT', 'MATCH_RECOGNIZE', 'NATURAL', 'OFFSET', 'ORDER', 'RIGHT', 'TABLESAMPLE', 'UNION', 'WHERE', 'WINDOW', <EOF>, <identifier>\", query_id=20251102_201216_00185_tsjew)\n"
     ]
    }
   ],
   "source": [
    "# Function to check data availability and time range\n",
    "def check_data_range(schema, table, timestamp_col='publish_timestamp'):\n",
    "    try:\n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as record_count,\n",
    "            from_unixtime(MIN({timestamp_col}) / 1000) as earliest_record,\n",
    "            from_unixtime(MAX({timestamp_col}) / 1000) as latest_record\n",
    "        FROM smartcities_iceberg.{schema}.\"{table}\"\n",
    "        \"\"\"\n",
    "        cur.execute(query)\n",
    "        result = cur.fetchone()\n",
    "        return {\n",
    "            'Schema': schema,\n",
    "            'Table': table,\n",
    "            'Record Count': result[0] if result else 0,\n",
    "            'Earliest': result[1] if result else None,\n",
    "            'Latest': result[2] if result else None\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'Schema': schema,\n",
    "            'Table': table,\n",
    "            'Error': str(e)\n",
    "        }\n",
    "\n",
    "\n",
    "# Check data ranges for key tables\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA AVAILABILITY AND TIME RANGES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "ranges = []\n",
    "tables_to_check = [\n",
    "    ('alexandria', 'bsm'),\n",
    "    ('alexandria', 'psm'),\n",
    "    ('alexandria', 'safety-event'),\n",
    "    ('alexandria', 'vehicle-count'),\n",
    "    ('falls-church', 'hiresdata'),\n",
    "]\n",
    "\n",
    "for schema, table in tables_to_check:\n",
    "    print(f\"\\nChecking {schema}.{table}...\")\n",
    "    range_info = check_data_range(schema, table)\n",
    "    ranges.append(range_info)\n",
    "    if 'Error' not in range_info:\n",
    "        print(f\"  Records: {range_info['Record Count']:,}\")\n",
    "        print(\n",
    "            f\"  Time range: {range_info['Earliest']} to {range_info['Latest']}\")\n",
    "    else:\n",
    "        print(f\"  Error: {range_info['Error']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "blqomcv0go",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAMPLE DATA: Alexandria BSM (Basic Safety Message)\n",
      "================================================================================\n",
      "         city   intersection           table  publish_timestamp  \\\n",
      "0  alexandria  glebe-potomac  alexandria.bsm   1762109170268000   \n",
      "1  alexandria  glebe-potomac  alexandria.bsm   1762109170366000   \n",
      "2  alexandria  glebe-potomac  alexandria.bsm   1762109170366000   \n",
      "3  alexandria  glebe-potomac  alexandria.bsm   1762109170366000   \n",
      "4  alexandria  glebe-potomac  alexandria.bsm   1762109170366000   \n",
      "\n",
      "     location_name source_type vendor_name vendor_version  misc  msg_cnt  ...  \\\n",
      "0  Glebe & Potomac        ittf        derq           rev1  V2.2      127  ...   \n",
      "1  Glebe & Potomac        ittf        derq           rev1  V2.2       98  ...   \n",
      "2  Glebe & Potomac        ittf        derq           rev1  V2.2      125  ...   \n",
      "3  Glebe & Potomac        ittf        derq           rev1  V2.2       88  ...   \n",
      "4  Glebe & Potomac        ittf        derq           rev1  V2.2       23  ...   \n",
      "\n",
      "   brake_applied_status  traction_control_status  anti_lock_brake_status  \\\n",
      "0                     0                     None                    None   \n",
      "1                     0                     None                    None   \n",
      "2                     0                     None                    None   \n",
      "3                     0                     None                    None   \n",
      "4                     0                     None                    None   \n",
      "\n",
      "   stability_control_status  brake_boost_applied  auxiliary_brake_status  \\\n",
      "0                      None                 None                    None   \n",
      "1                      None                 None                    None   \n",
      "2                      None                 None                    None   \n",
      "3                      None                 None                    None   \n",
      "4                      None                 None                    None   \n",
      "\n",
      "   size_width  size_length original_content_type  \\\n",
      "0         190          450      application/json   \n",
      "1         190          450      application/json   \n",
      "2         203          589      application/json   \n",
      "3         190          450      application/json   \n",
      "4         190          450      application/json   \n",
      "\n",
      "                                    original_content  \n",
      "0  b'{\"sourceType\": \"ittf\", \"locationName\": \"Gleb...  \n",
      "1  b'{\"sourceType\": \"ittf\", \"locationName\": \"Gleb...  \n",
      "2  b'{\"sourceType\": \"ittf\", \"locationName\": \"Gleb...  \n",
      "3  b'{\"sourceType\": \"ittf\", \"locationName\": \"Gleb...  \n",
      "4  b'{\"sourceType\": \"ittf\", \"locationName\": \"Gleb...  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Get sample data from BSM table (using cursor to avoid pandas warning)\n",
    "print(\"=\" * 80)\n",
    "print(\"SAMPLE DATA: Alexandria BSM (Basic Safety Message)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "SELECT *\n",
    "FROM smartcities_iceberg.alexandria.bsm\n",
    "LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "columns = [desc[0] for desc in cur.description]\n",
    "results = cur.fetchall()\n",
    "df_bsm = pd.DataFrame(results, columns=columns)\n",
    "print(df_bsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "p6jyxrlg2x",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAMPLE DATA: Alexandria Safety Events\n",
      "================================================================================\n",
      "  event_type                  event_id      time_at_site       detection_area  \\\n",
      "0        LCV  690786324fd3ef0012dcd06b  1762082786008000            South Leg   \n",
      "1        LCV  6906c2af86085d0012be2701  1762036335412000            South Leg   \n",
      "2         IC  6906dde90f79ab001299157d  1762043305433000  Intersection Center   \n",
      "3     NM-VRU  69078b0c86085d0012bf0dc1  1762084023089000            North Leg   \n",
      "4         IC  690789dd33ed800012f8ba2e  1762083724923000            South Leg   \n",
      "\n",
      "  camera_id direction movement      object1_class object2_class        city  \\\n",
      "0         0      None     None               None          None  alexandria   \n",
      "1         0      None     None               None          None  alexandria   \n",
      "2         0      None     None               None          None  alexandria   \n",
      "3         0      None     None  Passenger Vehicle    Pedestrian  alexandria   \n",
      "4         0      None     None               None          None  alexandria   \n",
      "\n",
      "    intersection                    table  publish_timestamp  \n",
      "0  glebe-potomac  alexandria.safety-event   1762102810661000  \n",
      "1  glebe-potomac  alexandria.safety-event   1762052408521000  \n",
      "2  glebe-potomac  alexandria.safety-event   1762059606584000  \n",
      "3  glebe-potomac  alexandria.safety-event   1762102810661000  \n",
      "4  glebe-potomac  alexandria.safety-event   1762102810661000  \n"
     ]
    }
   ],
   "source": [
    "# Get sample data from Safety Event table (using cursor to avoid pandas warning)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE DATA: Alexandria Safety Events\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "SELECT *\n",
    "FROM smartcities_iceberg.alexandria.\"safety-event\"\n",
    "LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "columns = [desc[0] for desc in cur.description]\n",
    "results = cur.fetchall()\n",
    "df_safety = pd.DataFrame(results, columns=columns)\n",
    "print(df_safety)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "v68sy8dltf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SAMPLE DATA: Falls Church - Median Travel Times\n",
      "================================================================================\n",
      "           city data_provider                           table  \\\n",
      "0  falls-church     MioVision  falls-church.mediantraveltimes   \n",
      "1  falls-church     MioVision  falls-church.mediantraveltimes   \n",
      "2  falls-church     MioVision  falls-church.mediantraveltimes   \n",
      "3  falls-church     MioVision  falls-church.mediantraveltimes   \n",
      "4  falls-church     MioVision  falls-church.mediantraveltimes   \n",
      "\n",
      "                    src_intersection_id src_intersection  \\\n",
      "0  1909c589-3cfa-4e8b-b759-792c667baa96      birch-broad   \n",
      "1  1909c589-3cfa-4e8b-b759-792c667baa96      birch-broad   \n",
      "2  1909c589-3cfa-4e8b-b759-792c667baa96      birch-broad   \n",
      "3  1909c589-3cfa-4e8b-b759-792c667baa96      birch-broad   \n",
      "4  1909c589-3cfa-4e8b-b759-792c667baa96      birch-broad   \n",
      "\n",
      "                src_intersection_name  src_intersection_lat  \\\n",
      "0  Birch Street and West Broad Street             38.893546   \n",
      "1  Birch Street and West Broad Street             38.893546   \n",
      "2  Birch Street and West Broad Street             38.893546   \n",
      "3  Birch Street and West Broad Street             38.893546   \n",
      "4  Birch Street and West Broad Street             38.893546   \n",
      "\n",
      "   src_intersection_long                  dest_intersection_id  \\\n",
      "0             -77.188643  0f45e46c-efc1-498a-91c3-f61cfad78ea8   \n",
      "1             -77.188643  0f45e46c-efc1-498a-91c3-f61cfad78ea8   \n",
      "2             -77.188643  0f45e46c-efc1-498a-91c3-f61cfad78ea8   \n",
      "3             -77.188643  0f45e46c-efc1-498a-91c3-f61cfad78ea8   \n",
      "4             -77.188643  0f45e46c-efc1-498a-91c3-f61cfad78ea8   \n",
      "\n",
      "  dest_intersection                         dest_intersection_name  \\\n",
      "0  broad-washington  East Broad Street and North Washington Street   \n",
      "1  broad-washington  East Broad Street and North Washington Street   \n",
      "2  broad-washington  East Broad Street and North Washington Street   \n",
      "3  broad-washington  East Broad Street and North Washington Street   \n",
      "4  broad-washington  East Broad Street and North Washington Street   \n",
      "\n",
      "   dest_intersection_lat  dest_intersection_long  publish_timestamp  \\\n",
      "0              38.882233              -77.171086   1760985908656000   \n",
      "1              38.882233              -77.171086   1760985908656000   \n",
      "2              38.882233              -77.171086   1760985908657000   \n",
      "3              38.882233              -77.171086   1760985908656000   \n",
      "4              38.882233              -77.171086   1760985908656000   \n",
      "\n",
      "   travel_start_time   travel_end_time  travel_median data_confidence  \\\n",
      "0   1760830903511000  1760830963511000              0            HIGH   \n",
      "1   1760831083511000  1760831143511000              0            HIGH   \n",
      "2   1760831143511000  1760831203511000              0            HIGH   \n",
      "3   1760830963511000  1760831023511000              0            HIGH   \n",
      "4   1760831023511000  1760831083511000              0            HIGH   \n",
      "\n",
      "                                    original_content  \n",
      "0  {startTime=2025-10-18T23:41:43.511Z, endTime=2...  \n",
      "1  {startTime=2025-10-18T23:44:43.511Z, endTime=2...  \n",
      "2  {startTime=2025-10-18T23:45:43.511Z, endTime=2...  \n",
      "3  {startTime=2025-10-18T23:42:43.511Z, endTime=2...  \n",
      "4  {startTime=2025-10-18T23:43:43.511Z, endTime=2...  \n"
     ]
    }
   ],
   "source": [
    "# Get sample data from Falls Church median travel times (using cursor to avoid pandas warning)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE DATA: Falls Church - Median Travel Times\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "SELECT *\n",
    "FROM smartcities_iceberg.\"falls-church\".mediantraveltimes\n",
    "LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "columns = [desc[0] for desc in cur.description]\n",
    "results = cur.fetchall()\n",
    "df_travel = pd.DataFrame(results, columns=columns)\n",
    "print(df_travel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xopxgvk0zdc",
   "metadata": {},
   "source": [
    "## API Summary\n",
    "\n",
    "This smart-cities API provides access to connected vehicle and traffic management data from multiple cities:\n",
    "\n",
    "### Available Data Types:\n",
    "\n",
    "1. **BSM (Basic Safety Message)**: Real-time vehicle position, speed, heading from connected vehicles\n",
    "2. **PSM (Pedestrian Safety Message)**: Pedestrian detection and safety data\n",
    "3. **Safety Events**: Detected safety conflicts and incidents\n",
    "4. **Vehicle/VRU Counts**: Traffic volume data\n",
    "5. **Speed Distribution**: Speed profiles across locations\n",
    "6. **High-Resolution Traffic Data**: Detailed signal performance metrics\n",
    "7. **Travel Times**: Corridor travel time measurements\n",
    "\n",
    "### Geographic Coverage:\n",
    "\n",
    "- Alexandria, VA\n",
    "- Falls Church, VA\n",
    "- CCI (Center for Connected Infrastructure)\n",
    "- VTTI (Virginia Tech Transportation Institute)\n",
    "\n",
    "### Data Collection Approaches:\n",
    "\n",
    "Run the cells below to see examples of collecting data over time periods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "q8l685650w",
   "metadata": {},
   "source": [
    "## Example 1: Collecting BSM Data Over a Time Period\n",
    "\n",
    "This example shows how to collect vehicle trajectory data (BSM) for a specific time range:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otvff2r5z",
   "metadata": {},
   "outputs": [],
   "source": "# Collect BSM data for the last 24 hours\n# Using SELECT * to get all columns - customize after verifying column names above\n# Note: publish_timestamp is a bigint (milliseconds since epoch)\n\ncur.execute(\"\"\"\nSELECT \n    from_unixtime(publish_timestamp / 1000) as timestamp,\n    *\nFROM smartcities_iceberg.alexandria.bsm\nWHERE publish_timestamp >= to_unixtime(current_timestamp - interval '24' hour) * 1000\nORDER BY publish_timestamp DESC\nLIMIT 1000\n\"\"\")\n\ncolumns = [desc[0] for desc in cur.description]\nresults = cur.fetchall()\ndf_bsm_daily = pd.DataFrame(results, columns=columns)\n\nprint(f\"Collected {len(df_bsm_daily)} BSM records from the last 24 hours\")\nprint(f\"\\nColumns available: {list(df_bsm_daily.columns)}\")\nprint(f\"\\nFirst few rows:\")\nprint(df_bsm_daily.head())\n\n# After seeing the columns, you can select specific ones like this:\n# columns_i_want = ['timestamp', 'publish_timestamp', 'lat', 'lon', 'speed', 'heading']\n# df_bsm_daily_filtered = df_bsm_daily[columns_i_want]"
  },
  {
   "cell_type": "markdown",
   "id": "vgetkelhpbi",
   "metadata": {},
   "source": [
    "## Example 2: Collecting Safety Events Over a Date Range\n",
    "\n",
    "This example shows how to collect safety event data between specific dates:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ytyxhosfeb",
   "metadata": {},
   "outputs": [],
   "source": "# Collect safety events for a specific date range\n# Using SELECT * to get all columns - customize after verifying column names above\n# Note: publish_timestamp is a bigint (milliseconds since epoch)\n\ncur.execute(\"\"\"\nSELECT \n    from_unixtime(publish_timestamp / 1000) as timestamp,\n    *\nFROM smartcities_iceberg.alexandria.\"safety-event\"\nWHERE publish_timestamp BETWEEN \n    to_unixtime(timestamp '2024-01-01 00:00:00') * 1000 AND \n    to_unixtime(timestamp '2024-12-31 23:59:59') * 1000\nORDER BY publish_timestamp DESC\n\"\"\")\n\ncolumns = [desc[0] for desc in cur.description]\nresults = cur.fetchall()\ndf_safety_events = pd.DataFrame(results, columns=columns)\n\nprint(f\"Collected {len(df_safety_events)} safety events\")\nprint(f\"\\nColumns available: {list(df_safety_events.columns)}\")\n\nif len(df_safety_events) > 0:\n    # Check if 'event_type' column exists before using it\n    if 'event_type' in df_safety_events.columns:\n        print(\"\\nEvent type breakdown:\")\n        print(df_safety_events['event_type'].value_counts())\n    print(f\"\\nFirst few rows:\")\n    print(df_safety_events.head())"
  },
  {
   "cell_type": "markdown",
   "id": "kojtnd5jhkj",
   "metadata": {},
   "source": [
    "## Example 3: Aggregated Traffic Data by Hour\n",
    "\n",
    "This example shows how to aggregate traffic metrics over time periods:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xhonfeub11b",
   "metadata": {},
   "outputs": [],
   "source": "# Aggregate vehicle counts by hour for the last 7 days\n# Note: publish_timestamp is a bigint (milliseconds since epoch)\n# Note: Adjust aggregation fields based on actual columns available\n\ncur.execute(\"\"\"\nSELECT \n    date_trunc('hour', from_unixtime(publish_timestamp / 1000)) as hour,\n    COUNT(*) as vehicle_count,\n    AVG(speed) as avg_speed,\n    MAX(speed) as max_speed,\n    MIN(speed) as min_speed\nFROM smartcities_iceberg.alexandria.bsm\nWHERE publish_timestamp >= to_unixtime(current_timestamp - interval '7' day) * 1000\nGROUP BY date_trunc('hour', from_unixtime(publish_timestamp / 1000))\nORDER BY hour DESC\n\"\"\")\n\ncolumns = [desc[0] for desc in cur.description]\nresults = cur.fetchall()\ndf_hourly_traffic = pd.DataFrame(results, columns=columns)\n\nprint(f\"Collected {len(df_hourly_traffic)} hourly aggregates\")\nprint(f\"\\nColumns: {list(df_hourly_traffic.columns)}\")\nprint(df_hourly_traffic.head(10))\n\n# Plot if matplotlib is available\ntry:\n    import matplotlib.pyplot as plt\n    \n    if len(df_hourly_traffic) > 0:\n        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n        \n        ax1.plot(df_hourly_traffic['hour'], df_hourly_traffic['vehicle_count'])\n        ax1.set_ylabel('Vehicle Count')\n        ax1.set_title('Hourly Vehicle Counts - Last 7 Days')\n        ax1.grid(True)\n        \n        ax2.plot(df_hourly_traffic['hour'], df_hourly_traffic['avg_speed'])\n        ax2.set_ylabel('Average Speed')\n        ax2.set_xlabel('Time')\n        ax2.set_title('Average Speed by Hour')\n        ax2.grid(True)\n        \n        plt.tight_layout()\n        plt.show()\nexcept ImportError:\n    print(\"\\nInstall matplotlib to visualize the data: %pip install matplotlib\")"
  },
  {
   "cell_type": "markdown",
   "id": "7810as7jw2",
   "metadata": {},
   "source": [
    "## Example 4: Batch Collection Over Multiple Days\n",
    "\n",
    "This example shows how to collect data in batches over a longer time period:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cwtlmu2957",
   "metadata": {},
   "outputs": [],
   "source": "from datetime import datetime, timedelta\n\n# Function to collect data in daily batches (using cursor to avoid pandas warning)\ndef collect_data_batches(start_date, end_date, table_schema, table_name, columns_to_select='*'):\n    \"\"\"\n    Collect data in daily batches to avoid memory issues with large datasets\n    \n    Args:\n        start_date: Start date (string or datetime)\n        end_date: End date (string or datetime)\n        table_schema: Database schema name\n        table_name: Table name\n        columns_to_select: Columns to select (default '*' for all columns)\n    \n    Returns:\n        List of dataframes, one per day\n    \"\"\"\n    if isinstance(start_date, str):\n        start_date = datetime.strptime(start_date, '%Y-%m-%d')\n    if isinstance(end_date, str):\n        end_date = datetime.strptime(end_date, '%Y-%m-%d')\n    \n    batches = []\n    current_date = start_date\n    \n    while current_date <= end_date:\n        next_date = current_date + timedelta(days=1)\n        \n        # Note: publish_timestamp is a bigint (milliseconds since epoch)\n        # Using SELECT * to get all columns, or specify columns_to_select\n        if columns_to_select == '*':\n            select_clause = \"from_unixtime(publish_timestamp / 1000) as timestamp, *\"\n        else:\n            select_clause = f\"from_unixtime(publish_timestamp / 1000) as timestamp, {columns_to_select}\"\n        \n        query = f\"\"\"\n        SELECT {select_clause}\n        FROM smartcities_iceberg.{table_schema}.\"{table_name}\"\n        WHERE publish_timestamp >= to_unixtime(timestamp '{current_date.strftime('%Y-%m-%d 00:00:00')}') * 1000\n          AND publish_timestamp < to_unixtime(timestamp '{next_date.strftime('%Y-%m-%d 00:00:00')}') * 1000\n        \"\"\"\n        \n        print(f\"Collecting data for {current_date.strftime('%Y-%m-%d')}...\")\n        \n        # Use cursor instead of pd.read_sql to avoid pandas warning\n        cur.execute(query)\n        columns = [desc[0] for desc in cur.description]\n        results = cur.fetchall()\n        df_batch = pd.DataFrame(results, columns=columns)\n        \n        print(f\"  Found {len(df_batch)} records\")\n        \n        if len(df_batch) > 0:\n            batches.append(df_batch)\n        \n        current_date = next_date\n    \n    return batches\n\n# Example: Collect safety events for a week in daily batches\nprint(\"=\" * 80)\nprint(\"Collecting safety events in daily batches...\")\nprint(\"=\" * 80)\n\n# Note: Using SELECT * to get all columns - adjust dates based on actual data availability\nbatches = collect_data_batches(\n    start_date='2024-01-01',\n    end_date='2024-01-07',\n    table_schema='alexandria',\n    table_name='safety-event',\n    columns_to_select='*'  # Get all columns\n)\n\nif batches:\n    # Combine all batches\n    df_all = pd.concat(batches, ignore_index=True)\n    print(f\"\\nTotal records collected: {len(df_all)}\")\n    print(f\"\\nColumns available: {list(df_all.columns)}\")\n    print(f\"\\nDate range: {df_all['timestamp'].min()} to {df_all['timestamp'].max()}\")\n    print(f\"\\nFirst few rows:\")\n    print(df_all.head())\nelse:\n    print(\"\\nNo data found in this date range\")"
  },
  {
   "cell_type": "markdown",
   "id": "1mjqsfi2sge",
   "metadata": {},
   "source": "## Tips for Data Collection\n\n### STEP 1: Always Verify Column Names First!\n\n**Run the schema verification cells at the beginning of this notebook to see actual column names.**\n\nDon't assume field names! Common mistakes:\n- ❌ `vehicle_id` - may not exist\n- ❌ `latitude`, `longitude` - actual names are `lat`, `lon`\n- ✅ Check the verification output to see real column names\n\n### STEP 2: Understand the Data Types\n\n**publish_timestamp is a BIGINT (Unix epoch in milliseconds)**\n\nSince `publish_timestamp` is stored as a bigint (milliseconds since Unix epoch), you need to convert it:\n\n**For display/conversion to readable timestamp:**\n```sql\nfrom_unixtime(publish_timestamp / 1000) as timestamp\n```\n\n**For time-based filtering:**\n```sql\nWHERE publish_timestamp >= to_unixtime(current_timestamp - interval '24' hour) * 1000\n```\n\n**For date range filtering:**\n```sql\nWHERE publish_timestamp BETWEEN \n    to_unixtime(timestamp '2024-01-01 00:00:00') * 1000 AND \n    to_unixtime(timestamp '2024-12-31 23:59:59') * 1000\n```\n\n**For aggregation:**\n```sql\ndate_trunc('hour', from_unixtime(publish_timestamp / 1000))\n```\n\n### STEP 3: Start with SELECT * \n\nWhen exploring a new table, always start with `SELECT *` to see all available columns:\n\n```python\ncur.execute(\"SELECT * FROM smartcities_iceberg.alexandria.bsm LIMIT 5\")\ncolumns = [desc[0] for desc in cur.description]\nresults = cur.fetchall()\ndf = pd.DataFrame(results, columns=columns)\nprint(df.columns.tolist())  # See what columns are actually available\n```\n\nThen filter in pandas after seeing the data:\n```python\ndf_filtered = df[['column1', 'column2', 'column3']]\n```\n\n### Performance Tips:\n1. **Verify column names first** - Run schema verification cells\n2. **Start with SELECT *** - See what's available before selecting specific columns\n3. **Add LIMIT**: Always test queries with LIMIT first to check structure\n4. **Use WHERE clauses**: Filter by publish_timestamp to reduce data volume\n5. **Aggregate when possible**: Use GROUP BY and aggregation functions (COUNT, AVG, etc.)\n6. **Batch large requests**: Use the batch collection function for multi-day/multi-week requests\n\n### Common Time Intervals:\n- Last hour: `to_unixtime(current_timestamp - interval '1' hour) * 1000`\n- Last 24 hours: `to_unixtime(current_timestamp - interval '24' hour) * 1000`\n- Last week: `to_unixtime(current_timestamp - interval '7' day) * 1000`\n- Last month: `to_unixtime(current_timestamp - interval '30' day) * 1000`\n\n### Key Tables for Traffic Safety Analysis:\n- **alexandria.bsm**: Vehicle trajectories (position, speed, acceleration)\n- **alexandria.safety-event**: Detected safety conflicts\n- **alexandria.vehicle-count**: Traffic volumes\n- **alexandria.speed-distribution**: Speed profiles\n- **falls-church.hiresdata**: High-resolution signal data\n- **falls-church.mediantraveltimes**: Travel time measurements"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}